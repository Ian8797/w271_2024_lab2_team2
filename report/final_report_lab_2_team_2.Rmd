---
title: | 
  | \vspace{-2cm} \large W271 Group Lab 2 Team 2
author: |
  | \normalsize Katt Painter, Bo He, Akanksha Chattopadhyay, Ian Vaimberg
output: 'pdf_document'  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(magrittr)
library(patchwork)

library(lubridate)

library(tsibble)
library(feasts)
library(forecast)

library(sandwich)
library(lmtest)

library(nycflights13)
library(blsR)

library(Matrix) 
library(data.table) 
library(stats)
library(fable)
library(tseries)
library(reprex)
library(stargazer)
```

\centerline{\textit{POV: 1997}}

## Context 

Climate science has emerged as a leading field of interest in the 20th century. Efforts to bring awareness to the impact of human intervention on the environment, such as the burning of fossil fuels, have proved fruitful. The Intergovernmental Panel on Climate Change (IPCC) has reinforced these efforts. In 1990 they released the First Climate Assessment Report stating that "human activities are substantially increasing the atmospheric concentration of greenhouse gases" (IPCC, 1990). Greenhouse gases are a group of gases, such as carbon dioxide, methane, and nitrous oxide, that when present in higher concentrations in the atmosphere, raise the surface temperate of the Earth. Carbon dioxide is the most abundant greenhouse gas that is produced from human activity, namely energy production via fossil fuel combustion. Since the industrial revolution, energy consumption from petroleum and natural gas sources has risen dramatically. This report aims to investigate the following questions: How have the levels of atmospheric CO2 changed over time? And, is there an identifiable pattern that will persist into the future? Forecasting atmospheric carbon dioxide concentrations allows scientists to measure the corresponding impact to the global environment and justify the need for human intervention in the opposite direction. 

## Data and Exploration 

```{r load and format data, echo=FALSE}
data <- datasets::co2

data <- data %>% 
  as_tsibble(data) %>% 
  mutate(month = as.factor(month(index)))
```

Charles Keeling was a research scientist who made it his life's work to survey the atmosphere in hopes of confirming Svante Arrhenius's theory that fossil fuel combustion is increasing the concentration of CO2 in the atmosphere. To this end, Keeling collected atmospheric CO2 concentration measurements at a number of sampling-stations including the Mauna Loa Observatory in Hawaii. These measurements were taken using a CO2 analyzer which detects the amount of infrared absorption present in a air sample and turns it into a mole fraction of CO2, defined as the total CO2 molecules divided by the total non-water vapor molecules in the air, measured in parts per million (ppm). This report uses the data collected at the Mauna Loa Observatory between January 1959 and December 1997. The dataset consists of 468 observations with each observation representing the monthly total atmospheric concentration of CO2 (ppm). The observations for February, March, and April 1964 were unavailable so the values in the dataset were generated via linear interpolation between the observations for January and May 1964. 

In order to better understand the characteristics of this time series, we conducted a exploratory analysis prior to modeling. Figure 1 shows the time series plot for CO2 concentration, its autocorrelation plot, and its partial autocorrelation plot. The time series plot shows a clear positive trend as well as the presence of seasonality. The autocorrelation plot provides evidence to support the presence of both trend and seasonality as it decays with increasing lags and shows a spike at about every twelfth lag, indicating a seasonal cycle. These characteristics were confirmed by conducting a STL decomposition which showed clear linear trend and seasonal oscillations. 

```{r time series plot, echo=FALSE, fig.width = 10, fig.height = 3}
time_series <- ggplot(data, aes(x=index, y=value)) +
  geom_line() +
  ylab("CO2 Concentration") +
  xlab("Time") +
  ggtitle("CO2 Concentration 1959 - 1997")

acf <- ggAcf(data$value, lag.max = 50) +
  ggtitle("ACF")

pacf <- ggPacf(data$value, lag.max = 50) +
  ggtitle("Partial ACF")

time_series + acf + pacf + plot_annotation(expression(italic('Figure 1. Time Series, ACF, and PACF')), theme=theme(plot.title=element_text(hjust=0.5)))
```

```{r seasonal decomp, echo = FALSE, warning = FALSE, message = FALSE, include=FALSE}
STL.model <- data |>
  model(
    STL(value ~ trend(window = 6) + season(window = "periodic"),
    robust = TRUE))
STL.model |>
  components() |>
  autoplot()
```

Since the time series showed a clear positive linear trend, we also conducted exploratory analysis on the average annual growth rate of CO2 concentrations. Figure 2 indicates that the average annual growth rate of atmospheric CO2 concentration follows a white noise process. While there appears to be some acceleration in the growth rates, the ACF appears to not capture this trend. The annual growth of CO2 appears to be mean reverting, implying that the average long-run annual growth rate is expected to stay between 0.2% and 0.6% holding all else constant. If we were to ramp up activities that further increase CO2 emissions, we could expect a clearer linear trend to emerge. 

```{r growth rate plots, echo=FALSE, fig.width = 10, fig.height = 3}
data <- data %>% mutate(month = as.factor(month(index)))

annual_growth <- data %>%
  mutate(growth_rate = difference(value, lag = 12)/value ) %>%
  index_by(year = year(index)) |>
  summarise(growth_rate = mean(growth_rate)) |>
  na.omit()

# Time series data 
time_series <- ggplot(annual_growth, aes(x=year, y=growth_rate)) +
  geom_line() +
  ylab("Annualized Growth Rate") +
  xlab("Time") +
  ggtitle("Mean CO2 Growth 1959 - 1997")

# ACF 
acf <- ggAcf(annual_growth$growth_rate) +
  ggtitle("ACF")

# PACF
pacf <- ggPacf(annual_growth$growth_rate) +
  ggtitle("Partial ACF")

time_series + acf + pacf + plot_annotation(expression(italic('Figure 2. Time Series, ACF, and PACF')), theme=theme(plot.title=element_text(hjust=0.5)))
```

## Models and Forecasts

While the exploratory analysis allows us to infer the underlying process of the time series, we cannot confirm this process without empirical modeling. In this section we will produce multiple models from the following classes, linear models and ARIMA models. Following the modeling and model evaluation, we will use the models to produce forecasts for what the CO2 concentration will be over the next 20 years. 

### *Linear Models*

Three linear models were considered, these models are describe by the following set of equations: 
\begin{align}
y_t=t+\epsilon_t
\end{align}
\begin{align}
y_t=t+t^2+\epsilon_t
\end{align}
\begin{align}
y_t=t+t^2+d_{2, t}+d_{3, t}+...+d_{11, t}+d_{12, t}+\epsilon_t
\end{align}
where $t$ is the time index (i.e., year-month) represented as an integer and $d$ is a dummy variable representing each month. For example $d_{2}$ would correspond to the month of February, $d_{3}$ would correspond to the month of March, and so on. 

The following table reports the coefficients that produce the best fit for each of the previously defined models. It also reports several performance metrics such as R-squared, adjusted R-squared, F statistics, etc. The table suggests that each model explains a large amount of the variation in CO2 emissions with adjusted R-squared values ranging from 0.97 to 0.99. This indicates that these models appear to perform extremely well. The p-values associated with each predictor are also significant, indicating that each predictor increases the explanatory power of the model. However, in order to determine the appropriateness of using linear models to estimate CO2 concentrations we must examine the residuals of each model. 

```{r  linear models, echo = FALSE, results='hide'}
data$month_since_start <- as.numeric(index(data) - min(index(data))) + 1

lm_model <- lm(value ~ month_since_start, data=data)

quad_model <- lm(value ~ month_since_start + I(month_since_start^2), data=data)

lm_seasonal_model <- lm(value ~ month_since_start  + I(month_since_start^2) + month, data=data)
```

```{r stargazer linear models, results = "asis", fig.width = 10, fig.height = 3, echo=FALSE, fig.pos="H"}
stargazer(
    lm_model, quad_model, lm_seasonal_model,
    type = "latex",
    float = FALSE, 
    title = "Estimated Linear Models",
    dep.var.caption  = "Response: Atmospheric CO2 Concentration",
    dep.var.labels   = "",
    header=FALSE,
    star.cutoffs = c(0.05, 0.01, 0.001),
    digits=2,
    no.space = TRUE, 
    column.sep.width = "1pt", 
    single.row = TRUE,
    covariate.labels = c(
        "Month Index",
        "Month Index$^{2}$",
        "Feb",
        "March",
        "April",
        "May",
        "June",
        "July",
        "Aug",
        "Sep",
        "Oct",
        "Nov",
        "Dec"
    ),
    font.size = "small"
)
```


Figure 3 shows the standardized residuals against the fitted values for each linear model. There are clear patterns present in each of these plots. The first model shows a U-shaped curve that indicates the model is under predicting CO2 concentrations that are in the mid-range and over predicting CO2 concentrations closer to the edges. Whereas the quadratic model appears to oscillate in whether it is over or under predicting CO2 concentrations. The polynomial model appears to also have a U-shaped pattern. However, compared to the first model, its errors appear to be larger, especially at edge values. Nevertheless, the residuals appear to be homoskedastic for all three models which suggests that no transformation (i.e., logarthmic) is needed. Overall, these plots suggest that linear models are not appropriate for this particular data set. They do not appear to adequately capture the underlying time series process. So we must turn to ARIMA models.   


```{r residual plots linear models, echo = FALSE, fig.width = 10, fig.height = 3}
lm_residual_data <- data.frame(
  predicted_values = fitted(lm_model),
  residuals = rstandard(lm_model)
)

quad_residual_data <- data.frame(
  predicted_values = fitted(quad_model),
  residuals = rstandard(quad_model)
)

poly_residual_data <- data.frame(
  predicted_values = fitted(lm_seasonal_model),
  residuals = rstandard(lm_seasonal_model)
)

lm_resid_plot <- ggplot(lm_residual_data, aes(x = predicted_values, y = residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  geom_smooth(se = FALSE, formula = y ~ x, method = "loess") +
  labs(title = "Linear Model (1)", y = "Standardized Residuals", x = "Fitted Values")

quad_resid_plot <- ggplot(quad_residual_data, aes(x = predicted_values, y = residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  geom_smooth(se = FALSE, formula = y ~ x, method = "loess") +
  labs(title = "Quadratic Model (2)", y = "", x = "Fitted Values")

poly_resid_plot <- ggplot(poly_residual_data, aes(x = predicted_values, y = residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  geom_smooth(se = FALSE, formula = y ~ x, method = "loess") +
  labs(title = "Polynomial Model (3)", 
       x = "Fitted Values", y = "")

(lm_resid_plot | quad_resid_plot | poly_resid_plot) + plot_annotation(expression(italic('Figure 3. Linear Model Evaluation')), theme=theme(plot.title=element_text(hjust=0.5)))
```

### *ARIMA Models*

Due the strong presence of seasonality in the data, the next set of models are seasonal autoregressive integrated moving average models (SARIMA). The general notation (4) used to express these models is stated below as well as the short hand notation (5). 

\begin{align}
\phi(B)\Phi(B^s)(1-B)^d(1-B^s)^Dx_t=\mu+\theta(B)\Theta(B^s)\epsilon_t
\end{align}
\begin{align}
SARIMA(p, d, q)(P, D, Q)_s
\end{align}

These models include moving average (MA) terms, autoregressive (AR) terms, and differencing (D) terms at non-seasonal and seasonal lags. This allows the model to more accurately capture and account for the seasonality present in the data. To help determine the seasonal MA, AR, and D terms we took a first difference of the data and re-plotted Figure 1 with the differenced data. Figure 4 shows this plot. The plot indicates that after one difference the data is near stationary suggesting that the differencing term should be 1. We performed ADF and KPSS test to confirm stationarity. Moreover, the PACF shows a large spike followed by oscillations between positive and negative correlations which appear to weaken as the lag value increases. This indicates the presence of a higher order MA term. The plots do not appear to support the presence of a AR term. 

```{r stationary Test 1, echo=FALSE, warning=FALSE, include=FALSE}

adf_result <- adf.test(data$value)

kpss_result <- kpss.test(data$value)

paste("ADF Test p-value",adf_result$p.value)

paste("KPSS Test p-value",kpss_result$p.value)

data_diff <- data
data_diff$value_diff <- difference(data_diff$value) 

data_diff <- data_diff %>% 
  na.omit()

diff_adf_result <- adf.test(data_diff$value_diff)

diff_kpss_result <- kpss.test(data_diff$value_diff)

paste("ADF Test p-value",diff_adf_result$p.value)

paste("KPSS Test p-value",diff_kpss_result$p.value)

```

```{r time series plot differenced, echo=FALSE, fig.width = 10, fig.height = 3}
# Time series data 
time_series <- ggplot(data_diff, aes(x=index, y=value_diff)) +
  geom_line() +
  ylab("CO2 Concentration") +
  xlab("Time") +
  ggtitle("CO2 Concentration 1959 - 1997")

# ACF 
acf <- ggAcf(data_diff$value_diff, lag.max = 50) +
  ggtitle("ACF")

# PACF
pacf <- ggPacf(data_diff$value_diff, lag.max = 50) +
  ggtitle("Partial ACF")

time_series + acf + pacf + plot_annotation(expression(italic('Figure 4. Time Series, ACF, and PACF After First Difference')), theme=theme(plot.title=element_text(hjust=0.5)))
```

Based on the assessment of Figure 3, we fit three SARIMA models of the form: 

\begin{align}
SARIMA(0, 1, 1)(0, 1, 1)_{12}
\end{align}
\begin{align}
SARIMA(3, 1, 0)(3, 1, 0)_{12}
\end{align}
\begin{align}
SARIMA(0, 1, 1)(1, 1, 2)_{12}
\end{align}

The final model was selected using the BIC scores with the ultimate winner being the $SARIMA(0,1,1)(0,1,1)_{12}$ model with a BIC value of 194.7. BIC was chosen due to its inherent penalty on adding additional terms leading to a well fitted and simpler model. Finding the ideal model is done through grid search of various parameters as we employed three simultaneous searches to see the most variety of different model specialties. All searches included non-zero difference terms based on the our EDA while one model focused on AR terms, another MA terms and one finally on both at the same time. To further assess the appropriateness of this model, we looked at a residual ACF plot which closely resembles that of a white noise process with lags rarely falling outside of the 95% confidence interval around 0 correlation. We also conducted a Box-Ljung test which had a p-value greater than 0.05, therefore the residuals do not exhibit significant autocorrelation giving greater confidence that the SARIMA model found is appropriate to model the CO2 dataset. 

```{r ARIMA Modeling, echo = FALSE, warning = FALSE, message = FALSE, include=FALSE}
model_ma.bic<-data %>%
model(ARIMA(value ~ 1 + pdq(0,0:1,0:3) + PDQ(0,0:1,0:3), ic="bic", stepwise=F, greedy=F,
            order_constraint = p + q + P + Q <= 10))

model_ar.bic<-data %>%
model(ARIMA(value ~ 1 + pdq(0:3,0:1,0) + PDQ(0:3,0:1,0), ic="bic", stepwise=F, greedy=F,
           order_constraint = p + q + P + Q <= 10))

model_full.bic<-data %>%
model(ARIMA(value ~ 1 + pdq(0:3,0:1,0:3) + PDQ(0:3,0:1,0:3), ic="bic", stepwise=F, greedy=F,
            order_constraint = p + q + P + Q <= 10))

model_ma.bic %>% # Best BIC model to use for forecasting
  report()

model_ar.bic %>%
  report()

model_full.bic %>%
  report()
```

```{r residual ACF, echo = FALSE, warning = FALSE, message = FALSE, include=FALSE}
model_ma.bic %>%
augment() %>%
ACF(.resid) %>%
autoplot()
```

```{r box jenkins, echo = FALSE, warning = FALSE, message = FALSE, include=FALSE}
resid.ts<-model_ma.bic %>%
augment() %>%
pull(.resid) %>%
as.ts()

Box.test(resid.ts, lag = 10, type = "Ljung-Box")
```

### *Forecasts*

We used the models from equations 3 and 6 to generate forecasts of the expected atmospheric CO2 concentrations over the next 20 years. These forecasts are shown in Figure 5 below. The forecasts generated by each model appear to be similar in nature and both support that the trend and seasonal patterns present in the CO2 data will persist into the future. 

```{r poly and sarima forecast plot, echo=FALSE, fig.width = 6, fig.height = 4, fig.align='center'}
index <- seq(from = ymd("1998-01-01"), to = ymd("2020-12-01"), by = "1 month")

ext_data <- data.frame(index = index) %>%
  as_tsibble(index=index) %>%
  mutate(month = as.factor(month(index)))

ext_data$month_since_start <- seq(max(data$month_since_start)+1,max(data$month_since_start)+(23*12))

forecast <- data.frame(predict = predict(lm_seasonal_model, newdata = ext_data))

forecast$Month <- ext_data$index
forecast$Model <- 'Polynomial Seasonal'

start_year <- 1998
end_year <- 2022
number_of_forecast_periods <- (end_year - start_year) * 12 + 3 

forecasts_ma <- model_ma.bic %>% forecast(h = number_of_forecast_periods)

forecast_data <- as_tibble(forecasts_ma, .name_repair = "minimal") %>% 
  mutate(Model = "ARIMA MA")

forecast_data <- forecast_data %>%
  mutate(Month = ymd(paste(index, "01", sep = "-"))) %>%
  select(.mean, Month, Model) %>% 
  rename(predict = .mean)

combined_data <- rbind(forecast, forecast_data)

ggplot(data = combined_data) +
  geom_line(aes(x = Month, y = predict, colour = Model, linetype = Model)) +
  scale_color_manual(
    name = "Model",
    values = c("ARIMA MA" = "blue", "Polynomial Seasonal" = "darkgreen"),
    labels = c("SARIMA MA", "Polynomial Seasonal")
  ) +
  scale_linetype_manual(
    name = "Model",
    values = c("ARIMA MA" = "solid", "Polynomial Seasonal" = "solid"),
    labels = c("SARIMA MA", "Polynomial Seasonal")
  ) +
  guides(colour = guide_legend(order = 1), linetype = guide_legend(order = 1)) +
  labs(
    title = expression(italic("Figure 5. Polynomial and SARIMA Model Forecasts")),
    x = "Time",
    y = "CO2 Concentration"
  ) +
  theme_minimal()
```

We can also use the forecasts to determine the year and month that CO2 concentrations will surpass specified thresholds. In particular, we were interested in identifying when the CO2 is expected to be at 420 ppm and 500 ppm, respectively. Climate scientists have indicated that these thresholds are significant due to the associated impact to the global climate such as further global warming, extreme weather, ocean acidification, and other detrimental effects. The SARIMA model estimates that the CO2 concentration will reach 420 ppm for the first time at May 2023 and for the last time at November 2025. A 95% confidence interval indicates that first time at which this threshold will be reached may vary between May 2017 to May 2036 and the last time will vary between December 2018 and November 2039. The model estimates that CO2 concentration will reach 500 ppm for the first time at March 2053. The 95% confidence interval for this estimate varies between April 2040 and May 2078. The model estimates that CO2 concentration will reach 500 ppm for the last time at December 2053. The 95% confidence interval for this estimate varies between October 2041 and November 2080. Lastly, the model estimates that at 2100, the atmospheric CO2 concentration will reach 674 ppm. Confidence is low in all of these predictions due to the widening variance of the predictions over time. Despite the strong cyclical patterns forecasting this far out in time is an incredibly hard task to do accurately.

```{r Forecast atmospheric C02 growth, echo = FALSE, warning = FALSE, message = FALSE, include=FALSE}
model_ma.forecast_2100 <- forecast(model_ma.bic, h=103*12)

forecast_values <- model_ma.forecast_2100$value

i <- 1

f_level_420 <- list()
f_level_420_n <- list()
f_level_420_f <- list()

f_level_500 <- list()
f_level_500_n <- list()
f_level_500_f <- list()

l_level_420 <- list()
l_level_420_n <- list()
l_level_420_f <- list()

l_level_500 <- list()
l_level_500_n <- list()
l_level_500_f <- list()

for (f in forecast_values) {
  
  mu <- as.numeric(f[1])
  sigma <- as.numeric(f[2])
  
  if (mu >= 420) { # first at 420
     f_level_420 <- c(f_level_420, i)
  }
  
  if (mu + (2*sigma) >= 420) { # first at 420 (near term)
     f_level_420_n <- c(f_level_420_n, i)
  }
  
  if (mu - (2*sigma) >= 420) { # first at 420 (far term)
     f_level_420_f  <- c(f_level_420_f, i)
  }
  
  if (mu < 420) { # last at 420
     l_level_420 <- c(l_level_420, i)
  }
  
  if (mu + (2*sigma) < 420) { # last at 420 (near term)
     l_level_420_n <- c(l_level_420_n, i)
  }
  
  if (mu - (2*sigma) < 420) { # last at 420 (far term)
     l_level_420_f <- c(l_level_420_f, i)
  }
  
  
  if (mu >= 500) { # first at 500
     f_level_500 <- c(f_level_500, i)
  }
  
  if (mu + (2*sigma) >= 500) { # first at 500 (near term)
     f_level_500_n <- c(f_level_500_n, i)
  }
  
  if (mu - (2*sigma) >= 500) { # first at 500 (far term)
     f_level_500_f <- c(f_level_500_f, i)
  }
  
  
  if (mu < 500) { # last at 500
     l_level_500 <- c(l_level_500, i)
  }
  
  if (mu + (2*sigma) < 500) { # last at 500 (near term)
     l_level_500_n <- c(l_level_500_n, i)
  }
  
  if (mu - (2*sigma) < 500) { # last at 500 (far term)
     l_level_500_f <- c(l_level_500_f, i)
  }
  
  
  i <- i + 1

}

f_420_n <- model_ma.forecast_2100$index[f_level_420_n[[1]]]
f_420 <- model_ma.forecast_2100$index[f_level_420[[1]]]
f_420_f <- model_ma.forecast_2100$index[f_level_420_f[[1]]]

paste('Forecated mean first time at 420 ppm :',f_420)
paste('95% Range from:',f_420_n, 'to',f_420_f)

l_420_n <- model_ma.forecast_2100$index[l_level_420_n[[length(l_level_420_n)]]+1]
l_420 <- model_ma.forecast_2100$index[l_level_420[[length(l_level_420)]]+1]
l_420_f <- model_ma.forecast_2100$index[l_level_420_f[[length(l_level_420_f)]]+1]

paste('Forecated mean last time at 420 ppm :',l_420)
paste('95% Range from:',l_420_n, 'to',l_420_f)

f_500_n <- model_ma.forecast_2100$index[f_level_500_n[[1]]]
f_500 <- model_ma.forecast_2100$index[f_level_500[[1]]]
f_500_f <- model_ma.forecast_2100$index[f_level_500_f[[1]]]

paste('Forecated mean first time at 500 ppm :',f_500)
paste('95% Range from:',f_500_n, 'to',f_500_f)

l_500_n <- model_ma.forecast_2100$index[l_level_500_n[[length(l_level_500_n)]]+1]
l_500 <- model_ma.forecast_2100$index[l_level_500[[length(l_level_500)]]+1]
l_500_f <- model_ma.forecast_2100$index[l_level_500_f[[length(l_level_500_f)]]+1]

paste('Forecated mean last time at 500 ppm :',l_500)
paste('95% Range from:',l_500_n, 'to',l_500_f)

last_index <- length(model_ma.forecast_2100$index)
last_year <- last_index-11

prediction_2100 <- (mean(model_ma.forecast_2100$value[last_index]) + mean(model_ma.forecast_2100$value[last_year]))/2

paste('2100 C02 ppm prediction:',round(prediction_2100,2))
```

## Conclusions 

The primary questions posed at the beginning of this report were: How have the levels of atmospheric CO2 changed over time? And, is there an identifiable pattern that will persist into the future? The time series analysis conducted in this report addresses these questions. The levels of atmospheric CO2 have increased overtime. Moreover, there are seasonal and trend components in the data generation process that suggest the levels of atmospheric CO2 will continue to increase overtime at a relatively constant growth rate. It is important to understand that these conclusions are in the context of air samples taken at the Mauna Loa Observatory in Hawaii. To address this bias, it would be interesting to conduct the same analysis using data comprised of air samples from other land and sea stations around the world. Nevertheless, it is clear that there is a need for human intervention to decrease carbon dioxide emissions. Left unchecked carbon dioxide emissions will increase to a alarming point sometime between 2050 and 2100. 

\pagebreak
\centerline{\textit{POV: Present}}

Moving forward in this report, we will delve deeper into the evolution of atmospheric CO2 levels and draw comparisons between the patterns projected in the previous sections and those present in the current dataset. This analysis will leverage data sourced from the United States’ National Oceanic and Atmospheric Administration, collected at the Mauna Loa Observatory in Hawaii, consistent with our previous dataset. The data was compiled on a weekly basis, averaging CO2 values across days with valid data within each week. We retrieved the data by creating a data pipeline with the appropriate URL to the Global Monitoring Laboratory Website. Now we will examine the exploratory plots below to better understand the data.

```{r data pipeline, echo=FALSE}
weekly_co2_url <- "https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_weekly_mlo.csv"

content <- read_lines(weekly_co2_url, skip_empty_rows = TRUE)

header_end_index <- max(grep("^#", content))

co2_present <- read_csv(weekly_co2_url, skip = header_end_index, show_col_types = FALSE)

co2_present <- co2_present %>%
  mutate(date = make_date(year, month, day))

co2_present <- as_tsibble(co2_present, index = date)

co2_present <- co2_present[co2_present$average != -999.99, ]

co2_present <- co2_present %>%
  filter(year(date) >= 1997)

#head(co2_present)
```


```{r EDA PART 2,fig.width = 6, fig.height = 4, echo=FALSE, warning=FALSE, message=FALSE}
# Distribution 
dist <- ggplot(co2_present, aes(x = average)) +
  geom_histogram() + 
  ylab("Value") + 
  xlab("Frequency") + 
  ggtitle("CO2 Distribution")

# Time series data 
time_series <- ggplot(co2_present, aes(x=date, y=average)) +
  geom_line() +
  ylab("CO2 Concentration") +
  xlab("Year-Month") +
  ggtitle("CO2 Over Time")

# ACF 
acf <- ggAcf(co2_present$average, lag.max = 50) +
  ggtitle("ACF")

# PACF
pacf <- ggPacf(co2_present$average, lag.max = 50) +
  ggtitle("Partial ACF")

(time_series | acf) / (pacf | dist) 
```

The time series plot clearly shows an increasing trend in CO2 levels over time with regular seasonal fluctuations. This trend is consistent with the historical Keeling Curve data. The ACF plot reveals strong positive correlations at all lags, suggesting a very persistent and seasonal pattern in the CO2 data. In contrast, the PACF plot shows little to no significant correlations beyond the initial lag, implying that an autoregressive model may not be the best fit for this data. The distribution of CO2 concentrations indicates a multimodal distribution, suggesting the presence of different states in the data, potentially reflecting various environmental factors. With this understanding of our current data, we can now turn to compare it with the model forecasts from earlier sections of the report.

### Comparision of Linear and SARIMA Models with Present data

```{r month data, echo=FALSE}
co2_present <- read_csv(weekly_co2_url, skip = header_end_index, show_col_types = FALSE)

co2_present <- co2_present[co2_present$average != -999.99, ]

co2_monthly <- co2_present %>%
  group_by(year, month) %>%
  summarise(average = mean(average, na.rm = TRUE),
            .groups = "drop")

co2_monthly <- co2_monthly %>%
  mutate(Month = make_date(year, month, day = 1)) %>%
  select(-year, -month)  

co2_monthly_present <- as_tsibble(co2_monthly, index = Month)

#tail(co2_monthly_present)
```

```{r linear graph comp, echo=FALSE, warning=FALSE}
present_data <- co2_monthly_present %>%
  mutate(month_since_start = (year(Month) - 1959) * 12 + month(Month))

present_data$month <- as.numeric(format(present_data$Month, "%m"))

present_data <- present_data %>%
  mutate(month = month(Month))

present_data$month <- factor(present_data$month, levels = levels(factor(data$month)))

present_data$predicted_linear <- predict(lm_model, newdata = present_data)
present_data$predicted_quad <- predict(quad_model, newdata = present_data)
present_data$predicted_seasonal <- predict(lm_seasonal_model, newdata = present_data)

#present_data <- present_data %>%
  #filter(year(Month) > 1997) %>%
  #gather("Model", "CO2", c(predicted_linear, predicted_quad, predicted_seasonal, average))

present_data <- present_data %>%
  filter(year(Month) > 1997) %>%
  gather("Model", "CO2", c(predicted_linear, predicted_quad, predicted_seasonal, average)) %>%
  mutate(Model = case_when(
    Model == "predicted_linear" ~ "Linear Model",
    Model == "predicted_quad" ~ "Quadratic Model",
    Model == "predicted_seasonal" ~ "Seasonal Polynomial Model",
    TRUE ~ Model
  ))

line_comp <- ggplot(present_data, aes(x = Month, y = CO2, color = Model)) +
  geom_line() +
  labs(title = "Actual vs. Predicted Linear Models CO2 Levels", x = "Month", y = "CO2 Levels (ppm)") +
  theme_minimal()+
  scale_color_brewer(palette = "Set1",labels = c("Actual Values", "Linear Model", "Quadratic Model", "Seasonal Polynomial Model"))
```

```{r arima graph comp, echo=FALSE}
co2_monthly_present_comp <- co2_monthly_present %>%
  filter(year(Month) > 1997)

start_year <- 1998
end_year <- 2024
number_of_forecast_periods <- (end_year - start_year) * 12 + 3 

forecasts_ma <- model_ma.bic %>% forecast(h = number_of_forecast_periods)
forecasts_ar <- model_ar.bic %>% forecast(h = number_of_forecast_periods)
forecasts_full <- model_full.bic %>% forecast(h = number_of_forecast_periods)

forecast_data <- bind_rows(
  as_tibble(forecasts_ma, .name_repair = "minimal") %>% mutate(Model = "SARIMA MA"),
  as_tibble(forecasts_ar, .name_repair = "minimal") %>% mutate(Model = "SARIMA AR"),
  as_tibble(forecasts_full, .name_repair = "minimal") %>% mutate(Model = "SARIMA Full")
)

co2_monthly_present_comp <- as_tibble(co2_monthly_present_comp)
forecast_data <- as_tibble(forecast_data)

forecast_data <- forecast_data %>%
  mutate(Month = ymd(paste(index, "01", sep = "-"))) %>%
  select(-index) 

combined_data <- left_join(co2_monthly_present_comp, forecast_data, by = "Month")

arima_comp <- ggplot(data = combined_data) +
  geom_line(aes(x = Month, y = average, colour = "Actual", linetype = "Actual")) +
  geom_line(aes(x = Month, y = .mean, colour = Model, linetype = Model)) +
  scale_color_manual(
    name = "Model",
    values = c("Actual" = "red", "SARIMA AR" = "darkgreen", "SARIMA Full" = "blue", "SARIMA MA" = "pink"),
    labels = c("Actual Values", "SARIMA AR", "SARIMA Full", "SARIMA MA")
  ) +
  scale_linetype_manual(
    name = "Model",
    values = c("Actual" = "solid", "SARIMA AR" = "dotted", "SARIMA Full" = "dashed", "SARIMA MA" = "longdash"),
    labels = c("Actual Values", "SARIMA AR", "SARIMA Full", "SARIMA MA")
  ) +
  guides(colour = guide_legend(order = 1), linetype = guide_legend(order = 1)) +
  labs(
    title = "Actual vs. Predicted SARIMA Models CO2 Levels",
    x = "Month",
    y = "CO2 Levels"
  ) +
  theme_minimal()
```

```{r graphs,fig.width = 10, fig.height = 3, echo=FALSE}
(line_comp | arima_comp)
```

In the graph comparison of linear models, the forecast from the seasonal polynomial model aligns closely with the actual CO2 values. The simple linear model consistently underestimates the CO2 levels. The quadratic model shows an improved fit in terms of the overall upward trend compared to the simple linear model, but it doesn't fully capture the periodic seasonal variations. Turning to the SARIMA models, forecasts from all variants—AR, MA, and Full—align closely with the actual CO2 values. The Keeling Curve from 1997 to the present seems to have evolved pretty similarly to the historical curve.

In 1997, our forecasts estimated when atmospheric CO2 levels might first surpass the 420 ppm threshold. The best-performing model, SARIMA MA, suggests that this milestone would be reached in different years under various scenarios: May 2017 was projected as a high extreme case, May 2023 as the model's central prediction, and May 2036 as a low extreme case. Actual measurements extracted from the Mauna Loa Observatory indicate that this level was first crossed in April 2022. This outcome demonstrates that the Seasonal ARIMA model provided a reasonable estimation, with the actual occurrence falling between the predicted central and high extreme case scenarios. 

```{r accuracy comp, echo=FALSE}
subset_cd <- combined_data[c("Month", "average", "Model",".mean")]

present_data_sub <- present_data %>%
  rename(values = CO2)

subset_cd <- subset_cd %>%
  rename(values = .mean)

all_df <- full_join(present_data_sub, subset_cd, by = c("Month", "Model","values"))
all_df <- all_df[c("Month", "Model","values")]

actual_values <- all_df %>% 
  filter(Model == "average") %>% 
  select(values) %>% 
  unlist() %>% 
  ts(frequency = 12)  

accuracy_list <- list()

model_names <- c("Linear Model", "Quadratic Model", "Seasonal Polynomial Model", "SARIMA AR", "SARIMA MA", "SARIMA Full")

for(model_name in model_names) {
  predicted_values <- all_df %>% 
    filter(Model == model_name) %>% 
    select(values) %>% 
    unlist() %>% 
    ts(frequency = 12)  
  accuracy_list[[model_name]] <- accuracy(predicted_values, actual_values)
}

accuracy_df <- do.call(rbind, lapply(accuracy_list, function(x) {
  if (!is.null(x)) {
    
    data_frame <- as.data.frame(t(x[1:7]))
   
    names(data_frame) <- c("ME", "RMSE", "MAE", "MPE", "MAPE", "ACF1")
    return(data_frame)
  } 
}))

accuracy_df <- accuracy_df[c("ME", "RMSE", "MAE", "MPE", "MAPE", "ACF1")]
accuracy_df <- round(accuracy_df, 4)

print(accuracy_df)
```

Looking at the performance metrics of all three linear and SARIMA models, we see that the simple linear model shows high errors across all metrics. In contrast, both the quadratic and seasonal ploynomial models demonstrate lower error values, suggesting a more accurate representation of the data trends. The SARIMA models—SARIMA AR, SARIMA MA, and SARIMA Full—present moderate errors, with SARIMA MA and SARIMA Full yielding similar performance metrics. Among the models assessed, the seasonal polynomial model stands out with the lowest RMSE value at 0.5776, highlighting its accuracy in tracking the actual data points.

### Models

```{r Gap filling, echo = FALSE, results='hide', warning=FALSE, include=FALSE}
co2_monthly <- co2_monthly %>%
  mutate(Month = yearmonth(Month)) 

co2_monthly_present <- as_tsibble(co2_monthly, index = Month)

co2_monthly_present_gap_filled <- co2_monthly_present |>
  fill_gaps(average = 329.72)

scan_gaps(co2_monthly_present_gap_filled)
```

```{r STL, echo = FALSE, results='hide', warning=FALSE, include=FALSE}
seasonal.plot <- co2_monthly_present_gap_filled |>
  gg_subseries(average) +
  labs(y = "CO2 Concentration (Millions)", x = "Month",
       title = "Seasonal plot: CO2 Concentration in Mona Loa for 1975-2022")

seasonal.plot
```

As we have observed in our EDA section and observations from 1997 report, we believe the CO2 levels have both overall upward trend and very possible seasonal trend. We used STL decomposition to decompose the data into 3 components: 1) upward trend using 6 months window, 2) seasonal trend which is observed as yearly trend, and 3) remainder, which the mean is observed close to zero, and fluctuates around reasonably bounded variance. We will proceed with further investigation to check for stationary on the remainder.

```{r Task 5b STL, echo = FALSE, warning=FALSE}
STL.model <- co2_monthly_present_gap_filled |>
  model(
    STL(average ~ trend(window = 6) + season(window = "periodic"),
    robust = TRUE))
STL.model |>
  components() |>
  autoplot()
```

```{r STL part 2, echo = FALSE, warning=FALSE, include=FALSE}
STL.model.resids <- components(STL.model) |>
ACF(remainder) |>
autoplot() + labs(title = "Residuals of multiplicative decomposition")

STL.model.resids
```

```{r Box Test STL, echo = FALSE,  warning=FALSE, include=FALSE}
Box.test(components(STL.model)$remainder, lag = 10, type = "Ljung-Box")
```

From the residual plots and the Box-Ljung test results in p-value of 0.04 < 0.05, although the residuals of the decomposition appeared to be stationary, they do not appear to be completely white noise. This means that while the decomposition method eliminates the deterministic components from this specific time series, there are some correlation remains in the data. Combined with the knowledge that we learned from 1997 report, we decided to fit our data using SARIMA and polynomial time models with our new data.

```{r ARIMA, echo = FALSE,  warning=FALSE,  warning=FALSE, include=FALSE}
co2_monthly_present_gap_filled.train <- co2_monthly_present_gap_filled  |>
  filter(year(Month) < 2022)

co2_monthly_present_gap_filled.test <- co2_monthly_present_gap_filled  |>
  filter(year(Month) >= 2022)

models <- co2_monthly_present_gap_filled.train |>
  model(aic = ARIMA(average ~ pdq(0:10,0:2,0:10)+PDQ(0:3,0:1,0:3, period=12), ic="aic", stepwise=F, greedy=F),
  aicc = ARIMA(average ~ pdq(0:10,0:2,0:10)+PDQ(0:3,0:1,0:3, period=12), ic="aicc", stepwise=F, greedy=F),
  bic = ARIMA(average ~ pdq(0:10,0:2,0:10)+PDQ(0:3,0:1,0:3, period=12), ic="bic", stepwise=F, greedy=F))
```

Prior to model building, we have divided up our data to use data points prior to 2022 as our training dataset, and post 2022 as our testing dataset. Then, we start fitting SARIMA and polynomial time models using our training data and test the accuracy using the testing data.

```{r SARIMA residuals, echo = FALSE, warning=FALSE, include=FALSE}
models |>
 augment() |>
 ACF(.resid)|>
 autoplot()
```

```{r SARIMA models, warning=FALSE, include=FALSE}
models |>
  pivot_longer(everything(), names_to = "Model name", values_to = "SARIMA Model")
```

```{r SARIMA model comparison,  warning=FALSE, include=FALSE}
models |>
  report()
```

```{r SARIMA model selection 1, echo = FALSE,  warning=FALSE, include=FALSE}
SARIMA.model <- models |>
  select(.model=bic)  
SARIMA.model |> 
  augment() |>
  ggplot(aes(x = Month)) +
  geom_line(aes(y = average, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  labs(x = "Month", y = "CO2 Concentration (ppm)",
       title = "Mona Loa CO2 Concentration 1975-2022 (SARIMA model)")
```

### *SARIMA Model*

```{r SARIMA model selection 2, warning=FALSE, echo = FALSE}
SARIMA.model |>
  gg_tsresiduals() +
  labs(title = "SARIMA model residuals")
```

The residuals of SARIMA model appear to be close to white noise. There is no significant lags, but with some seasonal pattern that suggests we should run a statistical test on the residuals from the models to see if they are randomly distributed i.e. are white noise, which is what we want for a good model fit, or if they appear to have some serial correlation over time and violate the assumptions for a stationary time series fit. The Box-Ljung test result p-value of 0.53 > 0.05 confirmed that the residuals of the SARIMA model are stationary and appeared to be white noise. And we performed the similar steps and test on Polynomial model confirmed the same, so we decided to use both models for forecasting and accuracy comparison.

```{r SARIMA Box Ljung test, echo = FALSE,  warning=FALSE, include=FALSE}
models |>
  augment() |>
  filter(.model=="bic") |>
  select(.resid) %>%
  as.ts() %>%
  Box.test(., lag = 10, type = "Ljung-Box")
```

```{r forecasting using SARIMA, echo = FALSE,  warning=FALSE, include=FALSE}
SARIMA.forecast <- SARIMA.model |>
  forecast(co2_monthly_present_gap_filled.test) 

SARIMA.plot <- SARIMA.forecast  |>
  autoplot() +
  autolayer(co2_monthly_present_gap_filled.test) +
  geom_line(data=SARIMA.model |> augment() |>
  filter(year(Month) > 2020), aes(Month, .fitted)) +
  labs(title = "SARIMA model", x = "Month", y = "CO2 Concentration (ppm)")

sarima.accuracy <- accuracy(SARIMA.forecast, co2_monthly_present_gap_filled.test)

```

```{r polynomial time-trend model, echo = FALSE, fig.show='hide, warning=FALSE', include=FALSE}
polynomial_time_trend.model <- co2_monthly_present_gap_filled.train |>
 model(trend_model = TSLM(average ~ trend() + I(trend()^2) + season()))

polynomial_time_trend.model |>
  augment() |>
  ggplot(aes(x = Month)) +
  geom_line(aes(y = average, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  labs(x = "Month", y = "CO2 Concentration (ppm)",
       title = "Mona Loa CO2 Concentration 1975-2022 (Polynomial time trend model)")
```

```{r polynomial time-trend model summary, echo = FALSE, results='hide', warning=FALSE}
polynomial_time_trend.model |>
report()
```

```{r polynomial time-trend model forecast, echo = FALSE, warning=FALSE, include=FALSE}
poly.forecast <- polynomial_time_trend.model |>
  forecast(co2_monthly_present_gap_filled.test)

poly.plot <- poly.forecast  |>
  autoplot() +
  autolayer(co2_monthly_present_gap_filled.test) +
  geom_line(data=polynomial_time_trend.model |> augment() |>
  filter(year(Month) > 2020), aes(Month, .fitted)) +
  labs(title = "Polynomial time trend model", x = "Month", y = "CO2 Concentration (ppm)")

poly.accuracy <- accuracy(poly.forecast, co2_monthly_present_gap_filled.test)
```
```{r echo = FALSE, warning=FALSE}
SARIMA.plot / poly.plot
```

```{r accuracy table, echo = FALSE}
accuracy_table <- rbind(sarima.accuracy, poly.accuracy)
accuracy_table
```

From the above accuracy table, it is evident that SARIMA model has outperformed polynomial time-trend model in terms of minimize the forecast error in the test dataset. As a result, we have decided to use SARIMA model to forecast out fo 2122.

### *Forecast to 2122*

```{r forecast out to year 2122, echo = FALSE, warning=FALSE}
forecase.size = (2122-2020)*12
SARIMA.forecast.2122 <- SARIMA.model |>
  forecast(h=forecase.size) 

SARIMA.forecast.2122  |>
  autoplot() +
  geom_line(data=SARIMA.model |> augment() |>
  filter(year(Month) > 2020), aes(Month, .fitted)) +
  geom_hline(yintercept=500, linetype='longdash', col = 'red')+
  annotate("text", x = yearmonth("2040-01"), y = 500, label = "500 ppm", vjust = -0.5) +
  geom_hline(yintercept=420, linetype='longdash', col = 'orange')+
  annotate("text", x = yearmonth("2080-01"), y = 420, label = "420 ppm", vjust = -0.5) +
  labs(title = "Mona Loa CO2 Concentration Forecast (SARIMA model)", x = "Month", y = "CO2 Concentration (ppm)")

```

We can see that using our SARIMA model the forecasts also have a trend and seasonal movement and fluctuations increase overtime. But these forecasts will get very inaccurate as we move beyond at best 5 year forecasts of the model, as the confidence intervals of the model prediction begin to open up very widely due to the inherent model restriction and the unpredictability of the future. We can be pretty confident to say that we will hit 420 ppm CO2 level in 2023-2025, less confident about 500 ppm CO2 level as the model suggest it can be as early as 2045 or as late as 2060 or beyond.
