---
title: | 
  | \vspace{-2cm} \large W271 Group Lab 2 Team 2
author: |
  | \normalsize Katt Painter, Bo He, Akanksha Chattopadhyay, Ian Vaimberg
output: 'pdf_document'  
---

```{r}
install.packages("blsR")
install.packages("forecast")

```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(magrittr)
library(patchwork)

library(lubridate)

library(tsibble)
library(feasts)
library(forecast)

library(sandwich)
library(lmtest)

library(nycflights13)
library(blsR)

library(Matrix) 
library(data.table) 
library(stats)
library(fable)
library(tseries)
library(reprex)
library(stargazer)
```

\centerline{\textit{POV: 1997}}

## Context 

Climate science has emerged as a leading field of interest in the 20th century. Efforts to bring awareness to the impact of human intervention on the environment, such as the burning of fossil fuels, have proved fruitful. The Intergovernmental Panel on Climate Change (IPCC) has reinforced these efforts. In 1990 they released the First Climate Assessment Report stating that "human activities are substantially increasing the atmospheric concentration of greenhouse gases" (IPCC, 1990). Greenhouse gases are a group of gases, such as carbon dioxide, methane, and nitrous oxide, that when present in higher concentrations in the atmosphere, raise the surface temperate of the Earth. Carbon dioxide is the most abundant greenhouse gas that is produced from human activity, namely energy production via fossil fuel combustion. Since the industrial revolution, energy consumption from petroleum and natural gas sources has risen dramatically. This report aims to investigate the following questions: How have the levels of atmospheric CO2 changed over time? And, is there an identifiable pattern that will persist into the future? Forecasting atmospheric carbon dioxide concentrations allows scientists to measure the corresponding impact to the global environment and justify the need for human intervention in the opposite direction. 

## Data and Exploration 

```{r load and format data, echo=FALSE}
data <- datasets::co2

data <- data %>% 
  as_tsibble(data) %>% 
  mutate(month = as.factor(month(index)))
```

Charles Keeling was a research scientist who made it his life's work to survey the atmosphere in hopes of confirming Svante Arrhenius's theory that fossil fuel combustion is increasing the concentration of CO2 in the atmosphere. To this end, Keeling collected atmospheric CO2 concentration measurements at a number of sampling-stations including the Mauna Loa Observatory in Hawaii. These measurements were taken using a CO2 analyzer which detects the amount of infrared absorption present in a air sample and turns it into a mole fraction of CO2, defined as the total CO2 molecules divided by the total non-water vapor molecules in the air, measured in parts per million (ppm). This report uses the data collected at the Mauna Loa Observatory between January 1959 and December 1997. The dataset consists of 468 observations with each observation representing the monthly total atmospheric concentration of CO2 (ppm). The observations for February, March, and April 1964 were unavailable so the values in the dataset were generated via linear interpolation between the observations for January and May 1964. 

In order to better understand the characteristics of this time series, we conducted a exploratory analysis prior to modeling. Figure 1 shows the time series plot for CO2 concentration, its autocorrelation plot, and its partial autocorrelation plot. The time series plot shows a clear positive trend as well as the presence of seasonality. The autocorrelation plot provides evidence to support the presence of both trend and seasonality as it decays with increasing lags and shows a spike at about every twelfth lag, indicating a seasonal cycle. 

- Discuss seasonal/trend decomposition 
- What about growth rates?
  - Some acceleration to the growth rates 
  - Growth rate is mean reverting with given process 

```{r time series plot, echo=FALSE, fig.width = 10, fig.height = 3}
time_series <- ggplot(data, aes(x=index, y=value)) +
  geom_line() +
  ylab("CO2 Concentration") +
  xlab("Time") +
  ggtitle("CO2 Concentration 1959 - 1997")

acf <- ggAcf(data$value, lag.max = 50) +
  ggtitle("ACF")

pacf <- ggPacf(data$value, lag.max = 50) +
  ggtitle("Partial ACF")

time_series + acf + pacf + plot_annotation(expression(italic('Figure 1. Time Series, ACF, and PACF')), theme=theme(plot.title=element_text(hjust=0.5)))
```

## Models and Forecasts

While the exploratory analysis allows us to infer the underlying process of the time series, we cannot confirm this process without empirical modeling. In this section we will produce multiple models from the following classes, linear models and ARIMA models. Following the modeling and model evaluation, we will use the models to produce forecasts for what the CO2 concentration will be over the next 20 years. 

### *Linear Models*

Three linear models were considered, these models are describe by the following set of equations: 
\begin{align}
y_t=t+\epsilon_t
\end{align}
\begin{align}
y_t=t+t^2+\epsilon_t
\end{align}
\begin{align}
y_t=t+t^2+d_{2, t}+d_{3, t}+...+d_{11, t}+d_{12, t}+\epsilon_t
\end{align}
where $t$ is the time index (i.e., year-month) represented as an integer and $d$ is a dummy variable representing each month. For example $d_{2}$ would correspond to the month of February, $d_{3}$ would correspond to the month of March, and so on. 

The following table reports the coefficients that produce the best fit for each of the previously defined models. It also reports several performance metrics such as R-squared, adjusted R-squared, F statistics, etc. The table suggests that each model explains a large amount of the variation in CO2 emissions with adjusted R-squared values ranging from 0.97 to 0.99. This indicates that these models appear to perform extremely well. The p-values associated with each predictor are also significant, indicating that each predictor increases the explanatory power of the model. However, in order to determine the appropriateness of using linear models to estimate CO2 concentrations we must examine the residuals of each model. 

```{r  linear models, echo = FALSE, results='hide'}
data$month_since_start <- as.numeric(index(data) - min(index(data))) + 1

lm_model <- lm(value ~ month_since_start, data=data)

quad_model <- lm(value ~ month_since_start + I(month_since_start^2), data=data)

lm_seasonal_model <- lm(value ~ month_since_start  + I(month_since_start^2) + month, data=data)
```

```{r stargazer linear models, results = "asis", fig.width = 10, fig.height = 3, echo=FALSE, fig.pos="H"}
stargazer(
    lm_model, quad_model, lm_seasonal_model,
    type = "latex",
    float = FALSE, 
    title = "Estimated Linear Models",
    dep.var.caption  = "Response: Atmospheric CO2 Concentration",
    dep.var.labels   = "",
    header=FALSE,
    star.cutoffs = c(0.05, 0.01, 0.001),
    digits=2,
    no.space = TRUE, 
    column.sep.width = "1pt", 
    single.row = TRUE,
    covariate.labels = c(
        "Month Index",
        "Month Index$^{2}$",
        "Feb",
        "March",
        "April",
        "May",
        "June",
        "July",
        "Aug",
        "Sep",
        "Oct",
        "Nov",
        "Dec"
    ),
    font.size = "small"
)
```

Figure 2 shows the standardized residuals against the fitted values for each linear model. There are clear patterns present in each of these plots. The first model shows a U-shaped curve that indicates the model is under predicting CO2 concentrations that are in the mid-range and over predicting CO2 concentrations closer to the edges. Whereas the quadratic model appears to oscillate in whether it is over or under predicting CO2 concentrations. The polynomial model appears to also have a U-shaped pattern. However, compared to the first model, its errors appear to be larger, especially at edge values. Nevertheless, the residuals appear to be homoskedastic for all three models which suggests that no transformation (i.e., logarthmic) is needed. Overall, these plots suggest that linear models are not appropriate for this particular data set. They do not appear to adequately capture the underlying time series process. So we must turn to ARIMA models.   

```{r residual plots linear models, echo = FALSE, fig.width = 10, fig.height = 3}
lm_residual_data <- data.frame(
  predicted_values = fitted(lm_model),
  residuals = rstandard(lm_model)
)

quad_residual_data <- data.frame(
  predicted_values = fitted(quad_model),
  residuals = rstandard(quad_model)
)

poly_residual_data <- data.frame(
  predicted_values = fitted(lm_seasonal_model),
  residuals = rstandard(lm_seasonal_model)
)

lm_resid_plot <- ggplot(lm_residual_data, aes(x = predicted_values, y = residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  geom_smooth(se = FALSE, formula = y ~ x, method = "loess") +
  labs(title = "Linear Model (1)", y = "Standardized Residuals", x = "Fitted Values")

quad_resid_plot <- ggplot(quad_residual_data, aes(x = predicted_values, y = residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  geom_smooth(se = FALSE, formula = y ~ x, method = "loess") +
  labs(title = "Quadratic Model (2)", y = "", x = "Fitted Values")

poly_resid_plot <- ggplot(poly_residual_data, aes(x = predicted_values, y = residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  geom_smooth(se = FALSE, formula = y ~ x, method = "loess") +
  labs(title = "Polynomial Model (3)", 
       x = "Fitted Values", y = "")

(lm_resid_plot | quad_resid_plot | poly_resid_plot) + plot_annotation(expression(italic('Figure 2. Linear Model Evaluation')), theme=theme(plot.title=element_text(hjust=0.5)))
```

### *ARIMA Models*

Due the strong presence of seasonality in the data, the next set of models are seasonal autoregressive integrated moving average models (SARIMA). The general notation (4) used to express these models is stated below as well as the short hand notation (5). 

\begin{align}
\phi(B)\Phi(B^s)(1-B)^d(1-B^s)^Dx_t=\mu+\theta(B)\Theta(B^s)\epsilon_t
\end{align}
\begin{align}
SARIMA(p, d, q)(P, D, Q)_s
\end{align}

These models include moving average (MA) terms, autoregressive (AR) terms, and differencing (D) terms at non-seasonal and seasonal lags. This allows the model to more accurately capture and account for the seasonality present in the data. To help determine the seasonal MA, AR, and D terms we took a first difference of the data and re-plotted Figure 1 with the differenced data. Figure 2 shows this plot. The plot indicates that after one difference the data is near stationary suggesting that the differencing term should be 1. We performed ADF and KPSS test to confirm stationarity. Moreover, the PACF shows a large spike followed by oscillations between positive and negative correlations which appear to weaken as the lag value increases. This indicates the presence of a higher order MA term. The plots do not appear to support the presence of a AR term. 

```{r time series plot differenced, echo=FALSE, fig.width = 10, fig.height = 3}
data_diff <- data
data_diff$value_diff <- difference(data_diff$value)

# Time series data 
time_series <- ggplot(data_diff, aes(x=index, y=value_diff)) +
  geom_line() +
  ylab("CO2 Concentration") +
  xlab("Year-Month") +
  ggtitle("CO2 Concentration 1959 - 1997")

# ACF 
acf <- ggAcf(data_diff$value_diff, lag.max = 50) +
  ggtitle("ACF")

# PACF
pacf <- ggPacf(data_diff$value_diff, lag.max = 50) +
  ggtitle("Partial ACF")

time_series + acf + pacf + plot_annotation(expression(italic('Figure 2. Time Series, ACF, and PACF After First Difference')), theme=theme(plot.title=element_text(hjust=0.5)))
```

Based on the assessment of Figure 2, we fit three SARIMA models of the form: 

\begin{align}
SARIMA(0, 1, 1)(0, 1, 1)_{12}
\end{align}
\begin{align}
SARIMA(3, 1, 0)(3, 1, 0)_{12}
\end{align}
\begin{align}
SARIMA(0, 1, 1)(1, 1, 2)_{12}
\end{align}

The final model was selected using the BIC scores with the ultimate winner being the $SARIMA(0,1,1)(0,1,1)_{12}$ model with a BIC value of 194.7. BIC was chosen due to its inherent penalty on adding additional terms leading to a well fitted and simpler model. Finding the ideal model is done through grid search of various parameters as we employed three simultaneous searches to see the most variety of different model specialties. All searches included non-zero difference terms based on the our EDA while one model focused on AR terms, another MA terms and one finally on both at the same time. To further assess the appropriateness of this model, we looked at a residual ACF plot which closely resembles that of a white noise process with lags rarely falling outside of the 95% confidence interval around 0 correlation. This supports the use of the SARIMA model to model the CO2 dataset. 

```{r ARIMA Modeling, echo = FALSE, warning=FALSE}
model_ma.bic<-data %>%
model(ARIMA(value ~ 1 + pdq(0,0:1,0:3) + PDQ(0,0:1,0:3), ic="bic", stepwise=F, greedy=F,
             order_constraint = p + q + P + Q <= 10))
 
model_ar.bic<-data %>%
model(ARIMA(value ~ 1 + pdq(0:3,0:1,0) + PDQ(0:3,0:1,0), ic="bic", stepwise=F, greedy=F,
             order_constraint = p + q + P + Q <= 10))
 
model_full.bic<-data %>%
model(ARIMA(value ~ 1 + pdq(0:3,0:1,0:3) + PDQ(0:3,0:1,0:3), ic="bic", stepwise=F, greedy=F,
             order_constraint = p + q + P + Q <= 10))

#Report model summaries 
model_ma.bic %>% # Best BIC model to use for forecasting 
report()

model_ar.bic %>%
report()

model_full.bic %>%
report()
```

### *Forecasts*

```{r polynomial forecasts, echo = FALSE, results = 'hide',echo=FALSE,fig.width = 7, fig.height = 3}
index <- seq(from = ymd("1998-01-01"), to = ymd("2020-12-01"), by = "1 month")
# 
ext_data <- data.frame(index = index) %>% 
   as_tsibble(index=index) %>% 
   mutate(month = as.factor(month(index))) 

ext_data$month_since_start <- seq(max(data$month_since_start)+1,max(data$month_since_start)+(23*12))

forecast <- data.frame(predict = predict(lm_seasonal_model, newdata = ext_data))

forecast$index <- ext_data$index
# 
ggplot(forecast, aes(x=index, y=predict)) +
   geom_line() +
   ylab("CO2 Concentration") +
   xlab("Year-Month") +
   ggtitle("CO2 Concentration Forecast 1998 - 2020")
```

```{r ARIMA forcast 2022, echo=FALSE,fig.width = 7, fig.height = 3}
model_ma.forecasts<-forecast(model_ma.bic, h=25*12)
# 
autoplot(model_ma.forecasts) +
   autolayer(data, colour = "black", .vars = value) +
   xlab("Year") +
  ylab("Value") +
  ggtitle("ARIMA Forecast for Next 25 Years")
```

## Point of View from the Present 

Moving forward in this report, we will delve deeper into the evolution of atmospheric CO2 levels and draw comparisons between the patterns projected in the previous sections and those present in the current dataset. This analysis will leverage data sourced from the United States’ National Oceanic and Atmospheric Administration, collected at the Mauna Loa Observatory in Hawaii, consistent with our previous dataset. The data was compiled on a weekly basis, averaging CO2 values across days with valid data within each week. We retrieved the data by creating a data pipeline with the appropriate URL to the Global Monitoring Laboratory Website. Now we will examine the exploratory plots below to better understand the data.

```{r data pipeline, echo=FALSE}
weekly_co2_url <- "https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_weekly_mlo.csv"

content <- read_lines(weekly_co2_url, skip_empty_rows = TRUE)

header_end_index <- max(grep("^#", content))

co2_present <- read_csv(weekly_co2_url, skip = header_end_index, show_col_types = FALSE)

co2_present <- co2_present %>%
  mutate(date = make_date(year, month, day))

co2_present <- as_tsibble(co2_present, index = date)

co2_present <- co2_present[co2_present$average != -999.99, ]

co2_present <- co2_present %>%
  filter(year(date) >= 1997)

#head(co2_present)
```


```{r EDA PART 2,fig.width = 6, fig.height = 4, echo=FALSE, warning=FALSE}
# Distribution 
dist <- ggplot(co2_present, aes(x = average)) +
  geom_histogram() + 
  ylab("Value") + 
  xlab("Frequency") + 
  ggtitle("CO2 Distribution")

# Time series data 
time_series <- ggplot(co2_present, aes(x=date, y=average)) +
  geom_line() +
  ylab("CO2 Concentration") +
  xlab("Year-Month") +
  ggtitle("CO2 Over Time")

# ACF 
acf <- ggAcf(co2_present$average, lag.max = 50) +
  ggtitle("ACF")

# PACF
pacf <- ggPacf(co2_present$average, lag.max = 50) +
  ggtitle("Partial ACF")

(time_series | acf) / (pacf | dist) 
```

The time series plot clearly shows an increasing trend in CO2 levels over time with regular seasonal fluctuations. This trend is consistent with the historical Keeling Curve data. The ACF plot reveals strong positive correlations at all lags, suggesting a very persistent and seasonal pattern in the CO2 data. In contrast, the PACF plot shows little to no significant correlations beyond the initial lag, implying that an autoregressive model may not be the best fit for this data. The distribution of CO2 concentrations indicates a multimodal distribution, suggesting the presence of different states in the data, potentially reflecting various environmental factors. With this understanding of our current data, we can now turn to compare it with the model forecasts from earlier sections of the report.

### Comparision of Linear and SARIMA Models with Present data


```{r month data, echo=FALSE}

co2_present <- read_csv(weekly_co2_url, skip = header_end_index, show_col_types = FALSE)

co2_present <- co2_present[co2_present$average != -999.99, ]

co2_monthly <- co2_present %>%
  group_by(year, month) %>%
  summarise(average = mean(average, na.rm = TRUE),
            .groups = "drop")

co2_monthly <- co2_monthly %>%
  mutate(Month = make_date(year, month, day = 1)) %>%
  select(-year, -month)  

co2_monthly_present <- as_tsibble(co2_monthly, index = Month)

#tail(co2_monthly_present)
```


```{r linear graph comp, echo=FALSE, warning=FALSE}
present_data <- co2_monthly_present %>%
  mutate(month_since_start = (year(Month) - 1959) * 12 + month(Month))

present_data$month <- as.numeric(format(present_data$Month, "%m"))

present_data <- present_data %>%
  mutate(month = month(Month))

present_data$month <- factor(present_data$month, levels = levels(factor(data$month)))

present_data$predicted_linear <- predict(lm_model, newdata = present_data)
present_data$predicted_quad <- predict(quad_model, newdata = present_data)
present_data$predicted_seasonal <- predict(lm_seasonal_model, newdata = present_data)

#present_data <- present_data %>%
  #filter(year(Month) > 1997) %>%
  #gather("Model", "CO2", c(predicted_linear, predicted_quad, predicted_seasonal, average))

present_data <- present_data %>%
  filter(year(Month) > 1997) %>%
  gather("Model", "CO2", c(predicted_linear, predicted_quad, predicted_seasonal, average)) %>%
  mutate(Model = case_when(
    Model == "predicted_linear" ~ "Linear Model",
    Model == "predicted_quad" ~ "Quadratic Model",
    Model == "predicted_seasonal" ~ "Seasonal Polynomial Model",
    TRUE ~ Model
  ))

line_comp <- ggplot(present_data, aes(x = Month, y = CO2, color = Model)) +
  geom_line() +
  labs(title = "Actual vs. Predicted Linear Models CO2 Levels", x = "Month", y = "CO2 Levels (ppm)") +
  theme_minimal()+
  scale_color_brewer(palette = "Set1",labels = c("Actual Values", "Linear Model", "Quadratic Model", "Seasonal Polynomial Model"))




```

```{r arima graph comp, echo=FALSE}

co2_monthly_present_comp <- co2_monthly_present %>%
  filter(year(Month) > 1997)

start_year <- 1998
end_year <- 2024
number_of_forecast_periods <- (end_year - start_year) * 12 + 3 

forecasts_ma <- model_ma.bic %>% forecast(h = number_of_forecast_periods)
forecasts_ar <- model_ar.bic %>% forecast(h = number_of_forecast_periods)
forecasts_full <- model_full.bic %>% forecast(h = number_of_forecast_periods)

forecast_data <- bind_rows(
  as_tibble(forecasts_ma, .name_repair = "minimal") %>% mutate(Model = "SARIMA MA"),
  as_tibble(forecasts_ar, .name_repair = "minimal") %>% mutate(Model = "SARIMA AR"),
  as_tibble(forecasts_full, .name_repair = "minimal") %>% mutate(Model = "SARIMA Full")
)


co2_monthly_present_comp <- as_tibble(co2_monthly_present_comp)
forecast_data <- as_tibble(forecast_data)

forecast_data <- forecast_data %>%
  mutate(Month = ymd(paste(index, "01", sep = "-"))) %>%
  select(-index) 

combined_data <- left_join(co2_monthly_present_comp, forecast_data, by = "Month")


arima_comp <- ggplot(data = combined_data) +
  geom_line(aes(x = Month, y = average, colour = "Actual", linetype = "Actual")) +
  geom_line(aes(x = Month, y = .mean, colour = Model, linetype = Model)) +
  scale_color_manual(
    name = "Model",
    values = c("Actual" = "red", "SARIMA AR" = "darkgreen", "SARIMA Full" = "blue", "SARIMA MA" = "pink"),
    labels = c("Actual Values", "SARIMA AR", "SARIMA Full", "SARIMA MA")
  ) +
  scale_linetype_manual(
    name = "Model",
    values = c("Actual" = "solid", "SARIMA AR" = "dotted", "SARIMA Full" = "dashed", "SARIMA MA" = "longdash"),
    labels = c("Actual Values", "SARIMA AR", "SARIMA Full", "SARIMA MA")
  ) +
  guides(colour = guide_legend(order = 1), linetype = guide_legend(order = 1)) +
  labs(
    title = "Actual vs. Predicted SARIMA Models CO2 Levels",
    x = "Month",
    y = "CO2 Levels"
  ) +
  theme_minimal()


```


```{r graphs,fig.width = 10, fig.height = 3, echo=FALSE}

(line_comp | arima_comp)
```

In the graph comparison of linear models, the forecast from the seasonal polynomial model aligns closely with the actual CO2 values. The simple linear model consistently underestimates the CO2 levels. The quadratic model shows an improved fit in terms of the overall upward trend compared to the simple linear model, but it doesn't fully capture the periodic seasonal variations. Turning to the SARIMA models, forecasts from all variants—AR, MA, and Full—align closely with the actual CO2 values. The Keeling Curve from 1997 to the present seems to have evolved pretty similarly to the historical curve.

In 1997, our forecasts estimated when atmospheric CO2 levels might first surpass the 420 ppm threshold. The best-performing model, SARIMA MA, suggests that this milestone would be reached in different years under various scenarios: May 2017 was projected as a high extreme case, May 2023 as the model's central prediction, and May 2036 as a low extreme case. Actual measurements extracted from the Mauna Loa Observatory indicate that this level was first crossed in April 2022. This outcome demonstrates that the Seasonal ARIMA model provided a reasonable estimation, with the actual occurrence falling between the predicted central and high extreme case scenarios. 


```{r accuracy comp, echo=FALSE}

subset_cd <- combined_data[c("Month", "average", "Model",".mean")]

present_data_sub <- present_data %>%
  rename(values = CO2)

subset_cd <- subset_cd %>%
  rename(values = .mean)

all_df <- full_join(present_data_sub, subset_cd, by = c("Month", "Model","values"))
all_df <- all_df[c("Month", "Model","values")]

actual_values <- all_df %>% 
  filter(Model == "average") %>% 
  select(values) %>% 
  unlist() %>% 
  ts(frequency = 12)  

accuracy_list <- list()

model_names <- c("Linear Model", "Quadratic Model", "Seasonal Polynomial Model", "SARIMA AR", "SARIMA MA", "SARIMA Full")

for(model_name in model_names) {
  predicted_values <- all_df %>% 
    filter(Model == model_name) %>% 
    select(values) %>% 
    unlist() %>% 
    ts(frequency = 12)  
  accuracy_list[[model_name]] <- accuracy(predicted_values, actual_values)
}

accuracy_df <- do.call(rbind, lapply(accuracy_list, function(x) {
  if (!is.null(x)) {
    
    data_frame <- as.data.frame(t(x[1:7]))
   
    names(data_frame) <- c("ME", "RMSE", "MAE", "MPE", "MAPE", "ACF1")
    return(data_frame)
  } 
}))

accuracy_df <- accuracy_df[c("ME", "RMSE", "MAE", "MPE", "MAPE", "ACF1")]
accuracy_df <- round(accuracy_df, 4)

print(accuracy_df)
```

Looking at the performance metrics of all three linear and SARIMA models, we see that the simple linear model shows high errors across all metrics. In contrast, both the quadratic and seasonal ploynomial models demonstrate lower error values, suggesting a more accurate representation of the data trends. The SARIMA models—SARIMA AR, SARIMA MA, and SARIMA Full—present moderate errors, with SARIMA MA and SARIMA Full yielding similar performance metrics. Among the models assessed, the seasonal polynomial model stands out with the lowest RMSE value at 0.5776, highlighting its accuracy in tracking the actual data points.

### Models
